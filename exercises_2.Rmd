---
title: "exercises_2"
author: "Bas Machielsen"
date: '2022-07-12'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

```{r}
set.seed(55)

x <- runif(1000, -5, 5)
y <- x + rnorm(1000) + 3
```

```{r}
cost <- function(actual, prediction){
  
  return(mean((actual-prediction)^2))
  
}

```

```{r}

gradient_desc <- function(x, y, learn_rate, conv_threshold, n, max_iter) {
  plot(x, y, col = "blue", pch = 20)
  m <- 0
  c <- 0
  yhat <- m * x + c
  MSE <- sum((y - yhat) ^ 2) / n
  
  converged = F
  iterations = 0
  while(converged == F) {
    ## Implement the gradient descent algorithm
    m_new <- m - learn_rate * ((1 / n) * (sum((yhat - y) * x)))
    c_new <- c - learn_rate * ((1 / n) * (sum(yhat - y)))
    m <- m_new
    c <- c_new
    yhat <- m * x + c
    MSE_new <- sum((y - yhat) ^ 2) / n
    
    if(iterations %% 5 == 0){
      abline(c,m)
    }
    if(MSE - MSE_new <= conv_threshold) {
      abline(c, m) 
      converged = T
      return(paste("Optimal intercept:", c, "Optimal slope:", m))
    }
    iterations = iterations + 1
    if(iterations > max_iter) { 
      abline(c, m) 
      converged = T
      return(paste("Optimal intercept:", c, "Optimal slope:", m))
    }
  }
}

```

Set iteration number to 100 and the learning rate to 0.01. Initialize the intercept and slope to zero.

```{r}

gradient_desc(x, y, learn_rate = 0.01, 0.01, 1000, 100)

```

Keep the history and plot the cost function over time.

```{r}
plot_cost_function <- function(x, y, learn_rate, conv_threshold, n, max_iter) {
  
  m <- 0
  c <- 0
  yhat <- m * x + c
  MSE <- sum((y - yhat) ^ 2) / n
  
  mse_history <- vector(length = max_iter)
  mse_history[1] <- MSE
  
  converged = F
  iterations = 0
  while(converged == F) {
    ## Implement the gradient descent algorithm
    m_new <- m - learn_rate * ((1 / n) * (sum((yhat - y) * x)))
    c_new <- c - learn_rate * ((1 / n) * (sum(yhat - y)))
    m <- m_new
    c <- c_new
    yhat <- m * x + c
    MSE_new <- sum((y - yhat) ^ 2) / n
    
    if(MSE - MSE_new <= conv_threshold) {
      converged = T
      mse_history[iterations] <- MSE_new
      plot(mse_history, type = "S")
      return(paste("Optimal intercept:", c, "Optimal slope:", m))
    }
    iterations = iterations + 1
    mse_history[iterations] <- MSE_new
    
    if(iterations > max_iter) { 
      converged = T
      mse_history[iterations] <- MSE_new
      plot(mse_history, type = "S")
      return(paste("Optimal intercept:", c, "Optimal slope:", m))
    }
  }
  
}

```

```{r}
plot_cost_function(x, y, 0.01, 0.001, 1000, 100)
```

## First neural network

-   Load the Boston data and split it using set.seed(55) again.

```{r message=FALSE, output=FALSE}
library(MASS); library(tidyverse)
boston <- MASS::Boston

boston <- boston %>%
  mutate(dummy = if_else(medv > 20, 1, 0))
```

-   Scale the data and create a confusion matrix based on the standard logistic regression.

-   Create predictions (remember to scale also the test set). Report the accuracy.

## The remaining questions will be implemented in Python

-   Use the neuralnet package to create a simple neural network with 1 hidden layer, backprop algorithm, SSE cost function and a 0.1 learning rate parameter.

```{python}
import pandas as pd
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

from sklearn import preprocessing
from sklearn.model_selection import train_test_split

x_vars = pd.DataFrame(preprocessing.normalize(r.boston.iloc[:,0:13]))
y_var = r.boston['dummy'].copy()

X_train, X_test, y_train, y_test = train_test_split(
  x_vars, y_var, test_size=0.5, 
  random_state=55)

```

# build a neural network

```{python}
model = keras.Sequential()

model.add(layers.Dense(
    4, # Amount of Neurons
    input_dim=13, # Define an input dimension because this is the first layer
    activation='linear' # Use relu activation function because all inputs are positive
))

model.add(layers.Dense(
    1, # Amount of Neurons. We want one output
    activation='sigmoid' # Use sigmoid because we want to output a binary classification
))

model.compile(
    loss='mean_squared_error', # The loss function that is being minimized
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),
    metrics=['binary_accuracy', tf.keras.metrics.AUC()] 
)


```

```{python}
model.fit(
    X_train, # Input training data
    y_train, # Output training data
    epochs=1000, # Amount of iterations we want to train for
    verbose=0 # Amount of detail you want shown in terminal while training
)

```

-   Report the accuracy of this network after predicting the test set.

```{python}
model.test_on_batch(X_test, y_test, return_dict=True)

```

-   Now change the network architecture to c(8,2), which means 2 hidden layers with 8 and 2 neurons respectively. Is accuracy increased?

-   Apply early stopping and check the accuracy again.

-   Plot model architecture.

```{python}
tf.keras.utils.plot_model(model)

```




## MNIST

MNIST data

The MNIST is a database of handwritten digits, and is commonly used for training various image processing systems. The training set contains 60K examples, and the text set contains 10K examples.

- Load the data.

```{python}
from keras.datasets import mnist

(X_train, y_train), (X_test, y_test)  = mnist.load_data()

X_train.shape
```

- Create a min_max_normalization function, and apply it on the data.

```{python}
from sklearn.preprocessing import MinMaxScaler


scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)
X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)

```

- Plot the few of the images1.
    
```{python}
from matplotlib import pyplot
for i in range(9):  
  pyplot.subplot(3, 3, i+1)
  pyplot.imshow(train_X[i+5], cmap=pyplot.get_cmap('gray'))

pyplot.show()

```

- Use the nnet package and perform multinomial regression.

- Use the predict function to predict the test data.

- Create a confusion matrix2, and compute the accuracy. We will later compare it to our neural network model.

- Create a neural network model in Keras. Choose yourself the number of neurons, batch size, and the number of epochs. Use first a gradient descent optimizer.

```{python}
model = keras.Sequential()

model.add(tf.keras.Input(shape=(28,28)))

model.add(layers.Flatten())

model.add(layers.Dense(
  512, # Amount of Neuron # Define an input dimension because this is the first layer
  activation='relu' # Use relu activation function because all inputs are positive
))

model.add(layers.Dense(
    10, # Amount of Neurons. We want one output
    activation='softmax' # Use sigmoid because we want to output a binary classification
))

model.compile(
    loss= tf.keras.losses.SparseCategoricalCrossentropy(), # The loss function that is being minimized
    optimizer=tf.keras.optimizers.SGD(),
    metrics=['accuracy', 'mse'] 
)


```

```{python}
model.fit(
    X_train, # Input training data
    y_train, # Output training data
    epochs=5, # Amount of iterations we want to train for
    verbose=1 # Amount of detail you want shown in terminal while training
)

```

```{python}
from sklearn.metrics import confusion_matrix

predictions = model.predict(X_test).argmax(axis = 1)

confusion_matrix(y_test, predictions)
```

```{python}
model.summary()
```

- Keep all your chosen settings, but use the ADAM optimizer now.
